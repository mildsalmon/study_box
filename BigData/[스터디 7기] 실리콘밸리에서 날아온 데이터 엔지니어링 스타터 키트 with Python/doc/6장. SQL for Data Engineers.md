> 백엔드 엔지니어들이 사용하는 SQL은 production db에서 사용하는 SQL이라 응답속도가 중요하다.
> 데이터의 크기보다 속도가 중요.

> 데이터 엔지니어들이 사용하는(DW에서 사용하는) SQL은 데이터의 크기가 크고 속도가 덜 중요함.
> 데이터 분석에 사용됨.

# 0. 지난주 SQL 숙제 리뷰

```sql

--timestamp에서 month 구하는 방법

TO_CHAR(A.ts, 'YYYY-MM') AS month
LEFT(A.ts, 7)
DATE_TRUNC('month', A.ts)
SUBSTRING(A.ts, 1, 7)

```

Redshift나 대부분의 SQL(관계형 DB)에서는 timestamp의 표준 포멧이 `YYYY-MM-DD...`이런 식임.

---

현업에서 일을 할때는 데이터가 완전히 깨끗하다고 보장할 수 없으니, 처음 사용하는 데이터는 무조건 의심하면서 사용해라.

꼭, 데이터 품질을 확인하는 습관이 필요하다.

---

- GROUP BY
	- 특정 레코드에서 특정 필드(특정 컬럼)을 기준으로 레코드들을 grouping해주는 것
	- 필드가 같은 레코드끼리 묶어라
		- 같이 묶인 것들 안에서 aggregation을 할 수 있다.

```sql

GROUP BY 1 == GROUP BY month == GROUP BY TO_CHAR(A.ts, 'YYYY-MM')

```

# 1. Why still SQL in the era^[시대] of Big Data?

## A. Easy to Use and Vetted over Time

- SQL was originally developed in IBM in early 70s
- Best language to work with structured data (Relational Database)
	- Data  is stored in tables (structured) with records (rows) and fields (columns with types)
- There are two parts
	- DDL: Data Definition Language
		- CREATE TABLE, DROP TABLE, ALTER TABLE
	- DML: Data Manipulation Language
		- SELECT, INSERT INTO
- In mid 2000s it was less popular as new big data technologies emerged
	- But eventually all of them supported some forms of SQLs

---

- 구조화된 데이터를 처리하는데 있어 SQL보다 검증된 것이 없기 때문에 SQL이 사용되고 있음.
	- 큰 데이터라도 구조화된 데이터라면 SQL만큼 편리한게 없다.
- 똑같은 SQL이더라도 SQL이 돌아가는 환경에 따라 성능과 특성이 달라진다.
	- DW에서 돌아가는 SQL은 큰 데이터 processing에 초점이 맞춰져 있음
		- 속도는 빠르면 좋지만, 그렇게 중요한 point가 아님
	- PostgreSQL이나 MySQL에서 돌아가는 SQL은 속도가 중요
		- production db에서 사용하여 우리 서비스를 사용하는 사용자에게 바로 영향이 가는 SQL임.
		- 조금만 늦어져도 사용자는 불만을 표출함
- SQL 문법 자체는 데이터를 조작하는 문법일 뿐임.
	- 큰 데이터에 적용되느냐, 작은 데이터에 적용되느냐는 관계형 데이터베이스 자체에 의해서 결정된다.
- DDL (데이터 정의어)
	- 데이터의 구조를 정의
- DML (데이터 조작어)
	- 특정 레코드를 조회, 삭제, 삽입, 수정할 때 사용

## B. Disadvantage of SQL^[SQL의 단점]

### a. Not Great in Handling Unstructured Data

- Optimized for structured data handling
	- Regular expression and JSON can be used for unstructured data handling to a certain degree
	- Redshift can only handle a flat structure (not nested)
		- Big Query supports a nested structure (very powerful)
- Star schema isn’t always great vs. Denormalized schema
- There is no standard syntax (various SQL dialects)
	- Mostly similar though
- Not very flexible in handling semi-structured or unstructured data:
	- More flexible large scale unstructured data processing requires another framework
	- Spark, Hadoop (MapReduce -> Hive) and so on

---

- 데이터가 구조화되지 않았다면 SQL로 처리하기 어려움
	- 텍스트, 엑세스 로그 등은 `,`로 나뉘어 있지만, 정확하게 깨끗하게 나뉘는 파일 포멧이 아니라서 parsing을 해야함
- 대안으로 Spark같은 것이 나옴.
	- 어느 정도는 SQL도 사용할 수 있고
	- Spark도 pandas처럼 DataFrame이 있어서 프로그래밍 형태로 데이터를 조작할 수 있음
		- 내가 원하는 데이터 셋이 나올때까지 변환을 반복하는 구조가 된다.

# 2. 실습 전에 기억할 점

- 현업에서 깨끗한 데이터란 존재하지 않음
	- 항상 데이터를 믿을 수 있는지 **의심**할 껏! -> 의(疑)데이터증
	- 실제 레코드를 몇 개 살펴보는 것 만한 것이 없음 -> **노가다**
		- 테이블 이름, 필드 이름만 보고 끝내지 말고, 실제로 SELECT해서 데이터를 직접 봐라.
- 데이터 일을 한다면 항상 데이터의 품질을 의심하고 체크하는 버릇이 필요
	- **중복된 레코드**들 체크하기
	- **최근 데이터의 존재** 여부 체크하기 (freshness)
	- **Primary key uniqueness**가 지켜지는지 체크하기
	- **값이 비어있는 컬럼들**이 있는지 체크하기 
	- 위의 체크는 **코딩의 unit test 형태로 만들어 매번 쉽게 체크**해볼 수 있음
- 어느 시점이 되면 너무나 많은 테이블들이 존재하게 됨
	- 회사 성장과 밀접한 관련
	- 중요 테이블들이 무엇이고 그것들의 **메타 정보를 잘 관리**하는 것이 중요해짐
- 그 시점부터는 Data Discovery 문제들이 생겨남
	- 무슨 테이블에 내가 원하고 신뢰할 수 있는 정보가 들어있나?
	- 테이블에 대해 질문을 하고 싶은데 누구에게 질문을 해야하나?
- 이 문제를 해결하기 위한 다양한 오픈소스와 서비스들이 출현
	- DataHub (LinkedIn), Amundsen (Lyft), ... 
	- Select Star, DataFrame, …

# 3. SQL: DDL과 DML

## A. SQL 기본

- 먼저 다수의 SQL 문을 실행한다면 세미콜론으로 분리 필요
	- SQL문1; SQL문2; SQL문3;
- SQL 주석
	- -- : 인라인 한줄짜리 주석. 자바에서 //에 해당
	- \/\* -- \*\/: 여러 줄에 걸쳐 사용 가능한 주석
- SQL 키워드는 대문자를 사용한다던지 하는 나름대로의 포맷팅이 필요
	- 팀 프로젝트라면 팀에서 사용하는 공통 포맷이 필요
- 테이블/필드이름의 명명규칙을 정하는 것이 중요
	- 단수형 vs. 복수형
		- User vs. Users
	- _ vs. CamelCasing
		- user_session_channel vs. UserSessionChannel

## B. SQL DDL - 테이블 구조 정의 언어

### a. CREATE TABLE

- Primary key 속성을 지정할 수 있으나 무시됨
	- Primary key uniqueness
		- Big Data 데이터웨어하우스에서는 지켜지지 않음 (Redshift, Snowflake, BigQuery)
- CTAS: CREATE TABLE table_name AS SELECT 
	- vs. CREATE TABLE and then INSERT

> CTAS는 단점이 있음.
> > SELECT 결과에 의해서 테이블이 만들어지기 때문에, 만들어지는 테이블의 filed type을 내 마음대로 정하기가 어려움.
> > `INSERT INTO table_name SELECT * FROM ~`로 보완할 수 있음

```sql

CREATE TABLE raw_data.user_session_channel (
 userid int,
 sessionid varchar(32) primary key,
 channel varchar(32)
);

```

---

- DDL (Data Definition Language) - 테이블의 구조를 정의해주는 언어
- Big Data DW에서 primary key를 지원하려면, record가 들어갈 때마다 똑같은게 있는지 체크해야한다.
	- 그러다보면 속도가 안나서 큰 데이터를 loading할 수 없음.
	- 테이블을 만들때 primary key로 지정하는 것의 의미는 SQL optimizer한테 이 필드는 unique할거니까 그것을 힌트로 이 query를 최적화하라는 의미
		- 즉, 힌트임.
- CTAS
	- 테이블을 만듦과 동시에 데이터를 집어넣을 수 있음.
		- `CREATE TABLE ~ AS SELECT`

### b. DROP TABLE

- DROP TABLE
- DROP TABLE table_name;
	- 없는 테이블을 지우려고 하는 경우 에러를 냄
- DROP TABLE IF EXISTS table_name;
	- vs. DELETE FROM
		- DELETE FROM은 조건에 맞는 레코드들을 지움 (테이블 자체는 존재)

---

```sql

DROP TABLE IF EXISTS ~;

```

- DELETE FROM
	- 테이블은 존재
	- 삭제 후 되돌릴 수 있음
	- 테이블에서 모든 레코드를 삭제
	- WHERE 사용해 특정 레코드만 삭제 가능:
	- `DELETE  FROM raw_data.user_session_channel WHERE channel = ‘Google’`
- TRUNCATE TABLE
	- 테이블은 존재
	- 테이블에 있는 레코드, 인덱스를 전부 지움
	- 삭제 후 되돌릴 수 없음
	- DELETE보다 빠름
	- TRUNCATE이 전체 테이블의 내용 삭제시에는 여러모로 유리
	- 하지만 두가지 단점이 존재
		- TRUNCATE는 WHERE을 지원하지 않음
		- TRUNCATE는 Transaction을 지원하지 않음
- DROP TABLE
	- 테이블 자체를 지우는 것
	- 삭제 후 되돌릴 수 없음

### c. ALTER TABLE

- 새로운 **컬럼** 추가:
	- ALTER TABLE 테이블이름 ADD COLUMN 필드이름 필드타입;
- 기존 컬럼 이름 변경: 
	- ALTER TABLE 테이블이름 RENAME 현재필드이름 to 새필드이름
- 기존 컬럼 제거:
	- ALTER TABLE 테이블이름 DROP COLUMN 필드이름;
- 테이블 이름 변경:
 	- ALTER TABLE 현재테이블이름 RENAME to 새테이블이름;

## C. SQL DML - 테이블 레코드 조작 언어

### a. 레코드 질의 언어: SELECT

- SELECT FROM: 테이블에서 레코드와 필드를 읽어오는데 사용
- WHERE를 사용해서 레코드 선택 조건을 지정
- GROUP BY를 통해 정보를 그룹 레벨에서 뽑는데 사용하기도 함
	- DAU, WAU, MAU 계산은 GROUP BY를 필요로 함
- ORDER BY를 사용해서 레코드 순서를 결정하기도 함
- 보통 다수의 테이블의 조인해서 사용하기도 함

### b. 레코드 수정 언어: INSERT, UPDATE, DELETE

> DW에서는 `INSERT INTO`를 많이 사용하지는 않음
> > 엄청 큰 데이터(사용자 access data 등 몇 억개의 데이터)는 INSERT로 추가하면 시간이 너무 오래 걸림
> > DW계열에서는 INSERT에 해당하는 것이 `COPY` 명령어.
> > > record를 건 by 건으로 적재하는 것이 아니라, 레코드들이 들어간 파일을 만들고, 그 파일을 테이블에 bulk로 적재한다.

 INSERT INTO: 테이블에 레코드를 추가하는데 사용
 UPDATE FROM: 테이블 레코드의 필드 값 수정
 DELETE FROM: 테이블에서 레코드를 삭제
	 vs. TRUNCATE

# 4. Basic SQL

## A. SELECT

 테이블(들)에서 레코드들(혹은 레코드수)을 읽어오는데 사용
 WHERE를 사용해 조건을 만족하는 레코드

```sql

SELECT 필드이름1, 필드이름2, …
FROM 테이블이름
WHERE 선택조건
GROUP BY 필드이름1, 필드이름2, ...
ORDER BY 필드이름 [ASC|DESC] -- 필드 이름 대신에 숫자 사용 가능
LIMIT N;

```

```postgreSQL

-- IN

- WHERE channel in (‘Google’, ‘Youtube’)
	- WHERE channel = ‘Google’ OR channel = ‘Youtube’
- NOT IN

-- LIKE and ILIKE

- LIKE is a case sensitive string match. ILIKE is a case-insensitive string match
- WHERE channel LIKE ‘G%’ -> ‘G*’
- WHERE channel LIKE ‘%o%’ -> ‘*o*’ 
- NOT LIKE or NOT ILIKE

-- BETWEEN

- Used for date range matching

```

### a. STRING Functions

- LEFT(str, N)
	- 주어진 인자(str)에서 처음 N개의 문자를 가져온다.
- REPLACE(str, exp1, exp2)
- UPPER(str)
- LOWER(str)
- LEN(str)
- LPAD, RPAD
	- 주어진 길이만큼 padding해준다.
- SUBSTRING(str, first, length)
	- 주어진 인자(str)에서 first 위치부터 length 만큼의 문자를 가져온다.

## B. INSERT INTO vs COPY

- INSERT INTO is slower than COPY
	- COPY is a batch insertion mechanism.
	- COPY는 4주차에 사용 예정
- INSERT INTO table_name SELECT * FROM …
	- This is better than CTAS (CREATE TABLE table_name AS SELECT) if you want to control the types of the fields
		- But matching varchar length can be challenging
		- Snowflake and BigQuery support String type (no need to worry about string length)

---

- COPY 명령어는 bulk loading해주는 명령어
- record를 INSERT INTO처럼 건 by 건으로 삽입하는 것이 아니라 파일 형태로 bulk로 굉장히 큰 파일을 한번에 적재함.
- INSERT INTO도 CTAS처럼 사용할 수 있음

> CTAS는 단점이 있음.
> > SELECT 결과에 의해서 테이블이 만들어지기 때문에, 만들어지는 테이블의 filed type을 내 마음대로 정하기가 어려움.
> > `INSERT INTO table_name SELECT * FROM ~`로 보완할 수 있음

## C. ORDER BY

- Default ordering is ascending
	- `ORDER BY 1 ASC`
- Descending requires “DESC” 
	- `ORDER BY 1 DESC`
- Ordering by multiple columns:
	- `ORDER BY 1 DESC, 2, 3`
- NULL value ordering
	- By default, NULL values are ordered the last for ascending order 
	- By default, NULL values are ordered the first for descending order
	- You can change this with NULLS FIRST | NULLS LAST
		- `ORDER BY 1 DESC;` -- NULL값이 가장 앞에 옴
		- `ORDER BY 1 DESC NULLS LAST;` -- NULL값이 맨뒤로 이동

---

- RDB마다 NULL에 대한 설정이 다름
	- Redshift는 NULL을 가장 큰 값으로 봄.

## D. Type Cast and Conversion

- DATE Conversion:
	- CONVERT_TIMEZONE
		- CONVERT_TIMEZONE('America/Los_Angeles', ts)
		- select pg_timezone_names();
	- DATE, TRUNCATE
	- DATE_TRUNC
		- 첫번째 인자가 어떤 값을 추출하는지 지정 (week, month, day, …)
	- EXTRACT or DATE_PART: 날짜시간에서 특정 부분의 값을 추출가능
	- DATEDIFF, DATEADD, GET_CURRENT, ...
- Type Casting:
	- `cast` or `::` operator
	- category::int or cast(category as int)
- TO_CHAR, TO_TIMESTAMP

---

- 공통된 하나의 timestamp(UTC)를 사용하다가, 사용자의 지역에 맞춰 timezone을 바꿔서 표시하는게 제일 좋은 방법

## E. NULL

- 값이 존재하지 않음을 의미
	- 0이나 비어있는 string과는 다름을 분명히 인지
- `IS NULL` or `IS NOT NULL`
	- ~~`= NULL` or `<> NULL`~~
- Boolean 타입의 필드도 “IS TRUE” 혹은 “IS FALSE”로 비교
	- `AA Is Not False == AA Is True` the same?
		- **NO**
			- A: True, False, NULL -> WHERE A is True, WHERE A is not FALSE 
- LEFT JOIN시 매칭되는 것이 있는지 확인하는데 아주 유용
- NULL 값을 다른 값으로 변환하고 싶다면
	- `COALESCE`를 사용 (뒤에서 더 설명)
	- `NULLIF`
- NULL로 나누면? vs. 0으로 나누면?
	- **NULL / Error (divide by zero)**

# 5. JOIN

![](/bin/DE7_image/DE7_6_1.png)

## A. JOIN 문법

```sql

SELECT A.*, B.*
FROM raw_data.table1 A
____ JOIN raw_data.table2 B ON A.key1 = B.key1 and A.key2 = B.key2
WHERE A.ts >= '2019-01-01';

```

## B. JOIN시 고려해야할 점

- 스타 스키마에서는 항상 필요
- 먼저 **중복 레코드가 없고** **Primary Key의 uniqueness가 보장**됨을 체크
	- 아주 중요함!!!
- 조인하는 **테이블들간의 관계를 명확하게 정의**
	- One to one
		- 완전한 one to one: user_session_channel & session_timestamp
		- 한쪽이 부분집합이 되는 one to one: user_session_channel & session_transaction
	- One to many? (order vs order_items)
		- 이 경우 중복이 더 큰 문제됨 -> 증폭!!
	- Many to one?
		- 방향만 바꾸면 One to many로 보는 것과 사실상 동일. 
	- Many to many?
		- 이런 경우는 많지 않으며 이는 one to one이나 one to many로 바꾸는 것이 가능하다면 변환하여 조인하는 것이 덜 위험
- 어느 테이블을 베이스로 잡을지 (From에 사용할지) 결정해야함

## C. 테이블로 실습

![](/bin/DE7_image/DE7_6_2.png)

### a. INNER JOIN

1. 양쪽 테이블에서 매치가 되는 레코드들만 리턴함
2. 양쪽 테이블의 필드가 모두 채워진 상태로 리턴됨

```sql

SELECT * FROM raw_data.Vital v
JOIN raw_data.Alert a ON v.vitalID = a.vitalID;

```

![](/bin/DE7_image/DE7_6_4.png)

### b. LEFT JOIN

1. 왼쪽 테이블(Base)의 모든 레코드들을 리턴함
2. 오른쪽 테이블의 필드는 왼쪽 레코드와 매칭되는 경우에만 채워진 상태로 리턴됨

```sql

SELECT * FROM raw_data.Vital v
LEFT JOIN raw_data.Alert a ON v.vitalID = a.vitalID;

```

![](/bin/DE7_image/DE7_6_5.png)

### c. FULL JOIN

1. 왼쪽 테이블과 오른쪽 테이블의 모든 레코드들을 리턴함
2. 매칭되는 경우에만 양쪽 테이블들의 모든 필드들이 채워진 상태로 리턴됨

```sql

SELECT * FROM raw_data.Vital v
FULL JOIN raw_data.Alert a ON v.vitalID = a.vitalID;

```

![](/bin/DE7_image/DE7_6_6.png)

### d. CROSS JOIN

1. 왼쪽 테이블과 오른쪽 테이블의 모든 레코드들의 조합을 리턴함

```sql

SELECT * FROM raw_data.Vital v CROSS JOIN raw_data.Alert a;

```

![](/bin/DE7_image/DE7_6_3.png)

### e. SELF JOIN

1. 동일한 테이블을 alias를 달리해서 자기 자신과 조인함

```sql

SELECT * FROM raw_data.Vital v1
JOIN raw_data.Vital v2 ON v1.vitalID = v2.vitalID;

```

![](/bin/DE7_image/DE7_6_7.png)

# 6. Advanced SQL

## a. UNION, EXCEPT

- UNION (합집합)
	- 여러개의 테이블들이나 SELECT 결과를 하나의 결과로 합쳐줌
	- UNION vs. UNION ALL
		- UNION은 중복을 제거
- EXCEPT (MINUS)
	- 하나의 SELECT 결과에서 다른 SELECT 결과를 빼주는 것이 가능 
- INTERSECT (교집합)
	- 여러 개의 SELECT문에서 같은 레코드들만 찾아줌

## b. COALESCE, NULLIF

- COALESCE(Expression1, Expression2, …):
	- 첫번째 Expression부터 값이 NULL이 아닌 것이 나오면 그 값을 리턴하고 모두 NULL이면 NULL을 리턴한다.
	- NULL값을 다른 값으로 바꾸고 싶을 때 사용한다.
- NULLIF(Expression1, Expression2):
	- Expression1과 Expression2의 값이 같으면 NULL을 리턴한다

## c. WINDOW

- Syntax:
	- function(expression) OVER ( [ PARTITION BY expression] [ ORDER BY expression ] )
- [Useful functions](https://docs.aws.amazon.com/redshift/latest/dg/c_Window_functions.html):
	- ROW_NUMBER, FIRST_VALUE, LAST_VALUE
	- Math functions: AVG, SUM, COUNT, MAX, MIN, MEDIAN, NTH_VALUE

## d. SUB Query (CTE)

- SELECT를 하기 전에 임시 테이블을 만들어서 사용하는 것이 가능
	- 임시 테이블을 별도의 CREATE TABLE로 생성하는 것이 아니라 SELECT 문의 앞단에서 하나의 SQL 문으로 생성
- 문법은 아래와 같음 (channel이라는 임시 테이블을 생성)

```sql

WITH channel AS (select DISTINCT  channel from raw_data.user_session_channel),
WITH temp AS (select ...),
...
SELECT *
FROM channel c
JOIN temp t ON c.userId = t.userId

```

## e. JSON Parsing FUnctions

> PostgreSQL의 장점이 JSON parsing해주는 함수들이 많고, 기능이 좋은데, 그 중에 일부가 Redshift로 porting이 됨

- JSON의 포맷을 이미 아는 상황에서만 사용가능한 함수
- JSON String을 입력으로 받아 특정 필드의 값을 추출가능 (nested 구조 지원)
- 예제) [JSON_EXTRACT_PATH_TEXT](https://docs.aws.amazon.com/redshift/latest/dg/JSON_EXTRACT_PATH_TEXT.html)

```json

SELECT JSON_EXTRACT_PATH_TEXT('{"f2":{"f3":1},"f4":{"f5":99,"f6":"star"}}','f4', 'f6');

{
	"f2":{
		"f3":1
	},
	"f4":{
		"f5":99,
		"f6":"star"
	}
}

```

