# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.13.6
#   kernelspec:
#     display_name: big_data
#     language: python
#     name: big_data
# ---

# # Sparkì— ì˜í•œ ë¶„ì‚° í™˜ê²½

pyspark --packages org.mongodb.spark:mongo-spark-connector_2.11:2.2.0

# Sparkì„¸ì…˜ ì •ë³´ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
spark

# ### A. MongoDBì˜ ì• ë“œ í˜¹ ì§‘ê³„

# +
# MongoDBë¡œ ë¶€í„° ë°ì´í„°ê°€ì ¸ì™€ì„œ ë°ì´í„°í”„ë ˆì„ í˜•íƒœë¡œ ë³€ê²½
df = (spark.read
    .format("com.mongodb.spark.sql.DefaultSource")
    .option("uri", "mongodb://localhost/twitter.sample")
    .load())

# ë°ì´í„°í”„ë ˆì„ì„ ì¼ì‹œì ì¸ ë·°ë¡œ ë“±ë¡
df.createOrReplaceTempView('tweets')

# ì–¸ì–´ë³„ íŠ¸ìœ— ìˆ˜ì˜ ìƒìœ„ 3ê±´ í‘œì‹œí•˜ëŠ” ì¿¼ë¦¬ ì‘ì„±
query = '''
SELECT lang, count(*) count
FROM tweets 
WHERE delete IS NULL 
GROUP BY 1
ORDER BY 2 DESC
'''

# ì¿¼ë¦¬ ì‹¤í–‰
spark.sql(query).show(3)

# + active=""
# +----+------+
# |lang| count|
# +----+------+
# |  en|684768|
# |  ja|383212|
# | und|185301|
# +----+------+
# -
# ### B. í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°€ê³µ

# +
# ì˜ì–´ íŠ¸ìœ—ê³¼ ê¸€ì‘ì„± ì‹œê°„ ì¶”ì¶œ
en_query = '''
SELECT from_unixtime(timestamp_ms / 1000) time,
       text
FROM tweets
WHERE lang='en'
'''

# en_queryë¥¼ ì‹¤í–‰í•´ì„œ ë°ì´í„°í”„ë ˆì„ì„ ë§Œë“ ë‹¤.
en_tweets=spark.sql(en_query)

from pyspark.sql import Row

# íŠ¸ìœ—ì„ ë‹¨ì–´ë¡œ ë¶„í•´í•˜ëŠ” ì œë„¤ë ˆì´í„° í•¨ìˆ˜
def text_split(row):
    for word in row.text.split():
        yield Row(time=row.time, word=word)
        
# '.rdd'ë¡œ ì›ì‹œ ë ˆì½”ë“œ ì°¸ì¡°
en_tweets.rdd.take(1)

# + active=""
# [Row(time='2022-02-01 20:13:50', text='RT @Preeti_Nishad5: My idol has a wax statue at Madame Tussauds and his idol was invited for 2021 actors roundtable the difference ğŸ¤§ğŸ¤§')]
# -

# flatMap()ì— ì œë„¤ë ˆì´í„° í•¨ìˆ˜ ì ìš©
en_tweets.rdd.flatMap(text_split).take(2)

# + active=""
# [Row(time='2022-02-01 20:13:50', word='RT'), Row(time='2022-02-01 20:13:50', word='@Preeti_Nishad5:')]
# -

# toDF()ë¥¼ ì‚¬ìš©í•´ ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
en_tweets.rdd.flatMap(text_split).toDF().show(2)

# + -------------------+------------+ active=""
# +-------------------+----------------+
# |               time|            word|
# +-------------------+----------------+
# |2022-02-01 20:13:50|              RT|
# |2022-02-01 20:13:50|@Preeti_Nishad5:|
# +-------------------+----------------+
# only showing top 2 rows
# -

# ### C. Spark í”„ë¡œê·¸ë¨ì— ìˆì–´ì„œì˜ DAG ì‹¤í–‰

# +
# ë¶„í•´í•œ ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì§„ ë·° 'words'ë¥¼ ì‘ì„±
words = en_tweets.rdd.flatMap(text_split).toDF()
words.createOrReplaceTempView('words')

# ë‹¨ì–´ë³„ ì¹´ìš´íŠ¸ì˜ ìƒìœ„ 3ê±´ì„ í‘œì‹œ
word_count_query = '''
SELECT word, count(*) count
FROM words
GROUP BY 1
ORDER BY 2 DESC
'''

spark.sql(word_count_query).show(3)

# + active=""
# +----+------+
# |word| count|
# +----+------+
# |  RT|403096|
# | the|203869|
# |  to|161376|
# +----+------+
# only showing top 3 rows
# +
# ë¶„í•´í•œ ë‹¨ì–´ë¥¼ í…Œì´ë¸”ë¡œ ë³´ê´€
words.write.saveAsTable('twitter_sample_words')

# ì´ˆê¸° ì„¤ì •ì—ì„œëŠ” 'spark-warehouse'ì— íŒŒì¼ì´ ì €ì¥ëœë‹¤.
# ./spark-warehouse
# -


